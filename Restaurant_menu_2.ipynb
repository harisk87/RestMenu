{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import gensim\n",
    "from unidecode import unidecode\n",
    "import string\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "import random \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "food_categories = ['american','american-new','german','crepes','french','burgers','deli']#'asianfusion','californian','chinese','dim-sum','sandwiches'\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "\n",
    "base_url = url = 'http://www.allmenus.com/ca/san-francisco/'\n",
    "\n",
    "rest_url_list = []\n",
    "category_list = []\n",
    "\n",
    "print 'Scraping for urls'\n",
    "for fcat in food_categories:\n",
    "    # Get all the restaurants that food category falls into\n",
    "    top_page = requests.get(base_url + '-/' + fcat + '/',headers=headers)\n",
    "    \n",
    "    # Turn it into a BeautifulSoup object\n",
    "    top_soup= BeautifulSoup(top_page.text, \"lxml\")\n",
    "    all_rest_links = top_soup.findAll(\"p\",{\"class\",\"restaurant_name\"})\n",
    "    \n",
    "    for rest in all_rest_links:\n",
    "        rest_url_list.append(rest.find('a')['href'])\n",
    "        category_list.append(fcat)\n",
    "    \n",
    "print 'URLs obtained, time to scrape for menus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_menus(rest_url_list,category_list):\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    item_list = []\n",
    "    i=1\n",
    "    for url,fcat in zip(rest_url_list,category_list):\n",
    "        #print \"Scraping restaurant %d\"%(i)\n",
    "\n",
    "        page = requests.get('http://www.allmenus.com'+url,headers=headers)\n",
    "        soup = BeautifulSoup(page.text, \"lxml\")\n",
    "\n",
    "        # Extract restaurant name\n",
    "        name = unidecode(soup.find(\"h1\", {\"itemprop\":\"name\"}).text)\n",
    "\n",
    "        # Extract street address\n",
    "        saddr = unidecode(soup.find(\"span\",{\"itemprop\":\"streetAddress\"}).text)\n",
    "\n",
    "        # Extract the city\n",
    "        city = unidecode(soup.find(\"span\",{\"itemprop\":\"addressLocality\"}).text)\n",
    "\n",
    "        # Extract the state\n",
    "        state = unidecode(soup.find(\"span\",{\"itemprop\":\"addressRegion\"}).text)\n",
    "\n",
    "        # Extract the zip code\n",
    "        zipc = unidecode(soup.find(\"span\",{\"itemprop\":\"postalCode\"}).text)\n",
    "\n",
    "        # Extract yelp rating\n",
    "        try:\n",
    "            yelp_rating = float(soup.find(\"meta\",{\"itemprop\":\"ratingValue\"})['content'])\n",
    "        except:\n",
    "            yelp_rating = None\n",
    "\n",
    "        # Extract number of yelp reviews\n",
    "        try:\n",
    "            num_yelp_reviews = int(soup.find(\"meta\",{\"itemprop\":\"reviewCount\"})['content'])\n",
    "        except:\n",
    "            num_yelp_reviews = None\n",
    "\n",
    "        # Get the yelp link\n",
    "        try:\n",
    "            yelp_link = soup.find(\"span\",{\"class\":\"review_count\"}).find('a')['href']\n",
    "        except:\n",
    "            yelp_link = None\n",
    "\n",
    "        all_categories = soup.find_all(\"div\",{\"class\":\"category\"})\n",
    "\n",
    "        for cat in all_categories:\n",
    "            category_name = unidecode(cat.find(\"div\",{\"class\":\"category_head\"}).h3.text)\n",
    "            category_description = unidecode(cat.find(\"div\",{\"class\":\"category_head\"}).p.text)\n",
    "\n",
    "            all_menu_items_in_category = cat.find_all(\"li\",{\"class\":\"menu_item\"})\n",
    "\n",
    "            for menu_item in all_menu_items_in_category:\n",
    "                item_name = unidecode(menu_item.find(\"span\",{\"class\":\"name\"}).text)\n",
    "                item_description = unidecode(menu_item.find(\"p\",{\"class\":\"description\"}).text)\n",
    "                try:\n",
    "                    item_price = unidecode(menu_item.find(\"span\",{\"class\":\"price\"}).text)\n",
    "                except:\n",
    "                    item_price = []\n",
    "\n",
    "                new_item = {'restaurant_name':name, 'item_name':item_name,'item_description':item_description,'item_price':item_price,'category_name'\n",
    "                        :category_name,'category_description':category_description,'street_address':saddr,'city':city,\n",
    "                        'state':state,'zip':zipc,'full_address':\", \".join([saddr,city,state,zipc]),\"yelp_rating\":yelp_rating,\n",
    "                       'num_reviews':num_yelp_reviews,'yelp_link':yelp_link,'restaurant_category':fcat}\n",
    "                item_list.append(new_item)\n",
    "        i+=1\n",
    "\n",
    "    all_menus_rest_df = pd.DataFrame(item_list)\n",
    "    del item_list\n",
    "    return all_menus_rest_df\n",
    "    t1 = time.time()\n",
    "    print str(t1-t0) + 'seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pickled dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_menus_rest_df = pd.read_pickle('all_menus_rest_df.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all the duplicated entries (same restaurant, same address, same menu item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_menus_drop_dup = all_menus_rest_df.drop_duplicates(['restaurant_name','item_name','street_address'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the menu for Ti Couz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ti_couz_df = scrape_menus(['/ca/san-francisco/157991-ti-couz/menu/'],'crepes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some basic clean up for my example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harisk87/anaconda2/envs/my_projects_env/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "ti_couz_df.item_description[(ti_couz_df.category_name=='Krampouz Ble Noir - Savory Crepe')] = ti_couz_df.item_description[(ti_couz_df.category_name=='Krampouz Ble Noir - Savory Crepe')] + \" savory crepe\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harisk87/anaconda2/envs/my_projects_env/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "ti_couz_df.item_description[ti_couz_df.category_name=='Krampouz Froment - Sweet Crepe'] = ti_couz_df.item_description[ti_couz_df.category_name=='Krampouz Froment - Sweet Crepe'] +  \" sweet crepe\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the main dataframe with the Ti couz one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_menus_drop_dup = pd.concat([all_menus_drop_dup,ti_couz_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_menus_drop_dup['item_name_and_description'] = all_menus_drop_dup.item_name.map(str) + \" \" + all_menus_drop_dup.item_description.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def removePunctuation(df,col_name):\n",
    "    out_df = df[col_name].apply(lambda x: x.translate(string.maketrans(\"\",\"\"), string.punctuation))\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(df,col_name):\n",
    "    out_df = df[col_name].apply(lambda x: x.split())\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def removeStopWordsMakeLowerCase(df,col_name):\n",
    "    out_df = df[col_name].apply(lambda x: [i.lower() for i in x if i.lower() not in nltk.corpus.stopwords.words('english')]) \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatize(df,col_name):\n",
    "    from nltk.stem.wordnet import WordNetLemmatizer\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    out_df = [[lmtzr.lemmatize(unicode(i)) for i in x] for x in df[col_name]]\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeDuplicateWords(df,col_name):\n",
    "    out_df = [list(set(i)) for i in df[col_name]]\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_menus_drop_dup.item_name_and_description = removePunctuation(all_menus_drop_dup,'item_name_and_description')\n",
    "all_menus_drop_dup.item_name_and_description = tokenize(all_menus_drop_dup,'item_name_and_description')\n",
    "all_menus_drop_dup.item_name_and_description = removeStopWordsMakeLowerCase(all_menus_drop_dup,'item_name_and_description')\n",
    "all_menus_drop_dup.item_name_and_description = lemmatize(all_menus_drop_dup,'item_name_and_description')\n",
    "all_menus_drop_dup.item_name_and_description = removeDuplicateWords(all_menus_drop_dup,'item_name_and_description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tokens = all_menus_drop_dup.item_name_and_description.tolist()\n",
    "# new_tokens = all_menus_drop_dup.item_name_and_description_truncated.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_menus = all_menus_drop_dup.drop(['level_0','index','item_name_and_description','item_name_and_description_truncated','item_name_and_description_truncated_app_with_cat'],axis=1)\n",
    "all_menus['tokens'] = new_tokens\n",
    "all_menus.head()\n",
    "#all_menus_drop_dup['name_and_address'] = all_menus_drop_dup['restaurant_name'] + \" \" + all_menus_drop_dup['street_address']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START FROM HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load these first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_menus.to_pickle('all_menus.p')\n",
    "all_menus = pd.read_pickle('all_menus.p')\n",
    "\n",
    "#full_menus = all_menus.groupby('name_and_address').agg({'tokens': 'sum'}).reset_index()\n",
    "#full_menus.to_pickle('full_menus.p')\n",
    "full_menus = pd.read_pickle('full_menus.p')\n",
    "\n",
    "# pickle.dump(tokens, open( \"old_tokens.p\", \"wb\" ) )\n",
    "# old_tokens was obtained by removing punctuation, tokenizing, lemmatizing, making lower case and removing duplicate\n",
    "# words from items in menu\n",
    "old_tokens = pickle.load(open( \"old_tokens.p\", \"rb\" ))\n",
    "\n",
    "# pickle.dump(new_tokens, open( \"new_tokens.p\", \"wb\" ) )\n",
    "# new_tokens are the tokens gotten from taking old_tokens and\n",
    "# a) removing words that only appear once in corpus and\n",
    "# b) removing single letters and c) removing numbers\n",
    "new_tokens = pickle.load(open( \"new_tokens.p\", \"rb\" ))\n",
    "\n",
    "# pickle.dump(tfidf_mat_menus, open( \"tfidf_mat_menus.p\", \"wb\" ) )\n",
    "tfidf_mat_menus = pickle.load(open( \"tfidf_mat_menus.p\", \"rb\" ) )\n",
    "\n",
    "#pickle.dump(tfidf_mat_rests, open( \"tfidf_mat_rests.p\", \"wb\" ) )\n",
    "tfidf_mat_rests = pickle.load(open( \"tfidf_mat_rests.p\", \"rb\" ) )\n",
    "\n",
    "# pickle.dump(unique_rest_id_list, open( \"unique_rest_id_list.p\", \"wb\" ) )\n",
    "unique_rest_id_list = pickle.load(open( \"unique_rest_id_list.p\", \"rb\" ))\n",
    "\n",
    "#pickle.dump(restaurant_name_list, open( \"restaurant_name_list.p\", \"wb\" ) )\n",
    "restaurant_name_list = pickle.load(open( \"restaurant_name_list.p\", \"rb\" ) )\n",
    "\n",
    "#pickle.dump(restaurant_address_list, open( \"restaurant_address_list.p\", \"wb\" ) )\n",
    "restaurant_address_list = pickle.load(open( \"restaurant_address_list.p\", \"rb\" ) )\n",
    "\n",
    "#pickle.dump(name_and_addr_list, open( \"name_and_addr_list.p\", \"wb\" ) )\n",
    "name_and_addr_list = pickle.load(open( \"name_and_addr_list.p\", \"rb\" ) )\n",
    "\n",
    "def tfIdfMatCreator(new_tokens):\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    tfidf_model = TfidfVectorizer(tokenizer=lambda i:i, lowercase=False)\n",
    "    tfidf_mat = tfidf_model.fit_transform(tokens)\n",
    "    return tfidf_mat\n",
    "\n",
    "def getTopMatches(tfidf_mat,idx):\n",
    "    \n",
    "    # Compute the cosine similarity between the input idx and all the other vectors\n",
    "    cosine_similarities = cosine_similarity(tfidf_mat[idx], tfidf_mat).flatten()\n",
    "\n",
    "    # Organize the related food in descending order\n",
    "    related_idcs = cosine_similarities.argsort()[::-1]\n",
    "    \n",
    "    # Organize the cosine similarities in descending order\n",
    "    cosine_similarities_sorted = sorted(cosine_similarities, reverse=True)\n",
    "\n",
    "    # Remove the user input\n",
    "    user_selection = related_idcs[0]\n",
    "\n",
    "    # The rest of them\n",
    "    other_similar_items = related_idcs[1:]\n",
    "    \n",
    "    # Similarity metrics\n",
    "    return user_selection,other_similar_items,cosine_similarities_sorted[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the following code snippet if and only if you are planning to play with the minimum frequency of words you want to allow to remain in your corpus. Otherwise, skip the following step\n",
    "## If using this, ensure the dataframe is appended with the correct tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# d=defaultdict(int)\n",
    "# for item in old_tokens:\n",
    "#     for token in item:\n",
    "#         d[token]+=1\n",
    "        \n",
    "# min_freq = 1\n",
    "\n",
    "# over_one_token = [key for key,value in d.items() if value> min_freq]\n",
    "\n",
    "\n",
    "# new_tokens2 = [[word for word in document if (word in over_one_token) & (len(word) > 1) & (word.isalpha())] for document in old_tokens]\n",
    "# tfidf_mat_menus2 = tfIdfMatCreator(new_tokens2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tf-idf matrix using the tokens. For the rest of this exercise, we use new_tokens to be the ground truth correct, filtered version of our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 75026 is the index for crepe with mushroom sauce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runSim(idx=75026, all_menus=all_menus, full_menus=full_menus, new_tokens=new_tokens,\n",
    "          tfidf_mat_menus=tfidf_mat_menus, tfidf_mat_rests=tfidf_mat_rests, num_sim_items=5, num_sim_rests=5):\n",
    "\n",
    "    # idx  = 22000\n",
    "    # num_sim_items = 5\n",
    "    # num_sim_rests = 5\n",
    "\n",
    "    user_selection, other_similar_items, menu_cosine_similarities = getTopMatches(tfidf_mat_menus,idx)\n",
    "\n",
    "    # Pick the top num_sim_items items that aren't from the same restaurant\n",
    "    ctr = 0\n",
    "    top_num_sim_items_list = []\n",
    "    menu_cosine_similarity_list = []\n",
    "    for cos_sim,sim_item in zip(menu_cosine_similarities,other_similar_items):\n",
    "        if (all_menus.iloc[sim_item].name_and_address != all_menus.iloc[user_selection].name_and_address):\n",
    "            top_num_sim_items_list.append(sim_item)\n",
    "            menu_cosine_similarity_list.append(cos_sim)\n",
    "            ctr+=1\n",
    "            if ctr == num_sim_items:\n",
    "                break\n",
    "\n",
    "    ### VALIDATION\n",
    "\n",
    "    # Pick out the name and address of the input restaurant\n",
    "    name_and_address_of_input = all_menus.iloc[idx].name_and_address\n",
    "\n",
    "    # Get the row in the dataframe in which that particular menu item is located in\n",
    "    mat_row = full_menus[full_menus.name_and_address == name_and_address_of_input].index[0]\n",
    "\n",
    "    # Can later imagine trying to reduce search space to just restaurants in the same category\n",
    "    user_rest_selection, other_similar_rests, rest_cosine_similarities = getTopMatches(tfidf_mat_rests,mat_row)\n",
    "\n",
    "    # Get the tf idf matrix of rows only with the top num_sim_rests restaurant matches\n",
    "\n",
    "    similar_restaurant_list = full_menus.iloc[other_similar_rests[:5]].name_and_address.tolist()\n",
    "\n",
    "    all_items_in_rest_idcs = []\n",
    "    for rest in similar_restaurant_list:\n",
    "        all_items_in_rest_idcs.extend(all_menus[all_menus.name_and_address == rest].index.tolist())\n",
    "\n",
    "\n",
    "    ctr = 0\n",
    "    top_num_sim_items_list_constrained = []\n",
    "    menu_cosine_similarity_list_constrained = []\n",
    "    for cos_sim,sim_item in zip(menu_cosine_similarities,other_similar_items):\n",
    "        if sim_item in all_items_in_rest_idcs:\n",
    "            top_num_sim_items_list_constrained.append(sim_item)\n",
    "            menu_cosine_similarity_list_constrained.append(cos_sim)\n",
    "            ctr+=1\n",
    "            if ctr == num_sim_items:\n",
    "                break\n",
    "\n",
    "    mean_cosine_similarity_full = np.mean(menu_cosine_similarity_list)   \n",
    "    mean_cosine_similarity_constrained = np.mean(menu_cosine_similarity_list_constrained)   \n",
    "\n",
    "    lift = (mean_cosine_similarity_full - mean_cosine_similarity_constrained)/mean_cosine_similarity_constrained\n",
    "\n",
    "    #print \"lift is \" + str(lift*100) + \"%\"\n",
    "    return mean_cosine_similarity_full,mean_cosine_similarity_constrained,lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-357-9e4153a075d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_menus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunSim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mcos_sim_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mcost_sim_const_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-319-c35ee16b6091>\u001b[0m in \u001b[0;36mrunSim\u001b[1;34m(idx, all_menus, full_menus, new_tokens, tfidf_mat_menus, tfidf_mat_rests, num_sim_items, num_sim_rests)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# num_sim_rests = 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0muser_selection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother_similar_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmenu_cosine_similarities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetTopMatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_mat_menus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Pick the top num_sim_items items that aren't from the same restaurant\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-291-0ae95f8f664a>\u001b[0m in \u001b[0;36mgetTopMatches\u001b[1;34m(tfidf_mat, idx)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Organize the cosine similarities in descending order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mcosine_similarities_sorted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcosine_similarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# Remove the user input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "#test_list = random.sample(range(1, all_menus.shape[0]), 100)\n",
    "\n",
    "cos_sim_list = []\n",
    "cost_sim_const_list = []\n",
    "lift_list = []\n",
    "\n",
    "for t in range(all_menus.shape[0]):\n",
    "    a,b,c = runSim(idx=t)\n",
    "    cos_sim_list.append(a)\n",
    "    cost_sim_const_list.append(b)\n",
    "    lift_list.append(c)\n",
    "\n",
    "t1 = time.time()\n",
    "print t1-t0\n",
    "\n",
    "# 50588 completed in 70 minutes\n",
    "# total just over 75000, budget 2 hours for the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_list = [ i*100 for i in lift_list if i < 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 30.,  11.,   9.,  12.,   5.,   1.,   7.,   7.,   1.,   3.,   2.,\n",
       "          0.,   1.,   0.,   0.,   1.,   2.,   2.,   1.,   0.,   0.,   0.,\n",
       "          1.,   0.,   0.,   1.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "          0.,   0.,   0.,   0.,   0.,   1.]),\n",
       " array([   0.        ,   17.47208768,   34.94417536,   52.41626303,\n",
       "          69.88835071,   87.36043839,  104.83252607,  122.30461375,\n",
       "         139.77670142,  157.2487891 ,  174.72087678,  192.19296446,\n",
       "         209.66505214,  227.13713981,  244.60922749,  262.08131517,\n",
       "         279.55340285,  297.02549052,  314.4975782 ,  331.96966588,\n",
       "         349.44175356,  366.91384124,  384.38592891,  401.85801659,\n",
       "         419.33010427,  436.80219195,  454.27427963,  471.7463673 ,\n",
       "         489.21845498,  506.69054266,  524.16263034,  541.63471802,\n",
       "         559.10680569,  576.57889337,  594.05098105,  611.52306873,\n",
       "         628.99515641,  646.46724408,  663.93933176,  681.41141944,\n",
       "         698.88350712,  716.3555948 ,  733.82768247,  751.29977015,\n",
       "         768.77185783,  786.24394551,  803.71603319,  821.18812086,\n",
       "         838.66020854,  856.13229622,  873.6043839 ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEDCAYAAADOc0QpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f29e24577d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_list,bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names_and_address_list = all_menus.name_and_address.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_rest_id_list = [0]\n",
    "for i in range(len(names_and_address_list)):\n",
    "    if (i == 0) | (names_and_address_list[i] == names_and_address_list[i-1]):\n",
    "        continue\n",
    "    else:\n",
    "        unique_rest_id_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant_name_list = all_menus.restaurant_name.iloc[unique_rest_id_list]\n",
    "restaurant_address_list = all_menus.full_address.iloc[unique_rest_id_list]\n",
    "\n",
    "restaurant_name_list, restaurant_address_list = (list(x) for x in zip(*sorted(zip(restaurant_name_list, restaurant_address_list))))\n",
    "\n",
    "name_and_addr_list = [i + \", \" + j for i, j in zip(restaurant_name_list, restaurant_address_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTEMPTED LDA, DIDN'T WORK TOO WELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.8465759754\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "from gensim import corpora\n",
    "\n",
    "t0 = time.time()\n",
    "texts = menu_list\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "lda = models.LdaModel(corpus,num_topics=10,id2word=dictionary,passes=10)\n",
    "t1 = time.time()\n",
    "print t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 0.039125728427932133), (5, 0.22118166786478313), (8, 0.73710905063771959)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topic_prob_mat = lda[corpus]\n",
    "doc_topic_prob_mat[1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1013"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_menu_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length = full_menu_df.shape[0]\n",
    "\n",
    "topic_number_list = [None]*length\n",
    "topic_probability_list = [None]*length\n",
    "\n",
    "for i,prob_vec in enumerate(doc_topic_prob_mat):\n",
    "    tmp1, tmp2 = findTopic(prob_vec)\n",
    "    topic_number_list[i] = tmp1\n",
    "    topic_probability_list[i] = tmp2\n",
    "    \n",
    "    #topic_number_list.append(findTopic(prob_vec)[0])\n",
    "    \n",
    "    \n",
    "full_menu_df['topic_number'] = topic_number_list\n",
    "full_menu_df['topic_probability'] = topic_probability_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findTopic(prob_vec):\n",
    "    max_val = 0\n",
    "    max_topic = 100\n",
    "    for i,j in prob_vec:\n",
    "        if j > max_val:\n",
    "            max_val = j\n",
    "            max_topic = i\n",
    "\n",
    "    return max_val, max_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#google maps api\n",
    "#AIzaSyA16Kx4dQ_CbtlsqQe8RK5SsQBQU1BudxA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_description</th>\n",
       "      <th>category_name</th>\n",
       "      <th>city</th>\n",
       "      <th>full_address</th>\n",
       "      <th>item_description</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_price</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>restaurant_category</th>\n",
       "      <th>restaurant_name</th>\n",
       "      <th>state</th>\n",
       "      <th>street_address</th>\n",
       "      <th>yelp_link</th>\n",
       "      <th>yelp_rating</th>\n",
       "      <th>zip</th>\n",
       "      <th>name_and_address</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Dessert</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>1166 Geneva Ave, San Francisco, CA, 94112</td>\n",
       "      <td>poached kumquats, local honey</td>\n",
       "      <td>Blood Orange Panna Cotta</td>\n",
       "      <td>$6.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>american</td>\n",
       "      <td>Broken Record</td>\n",
       "      <td>CA</td>\n",
       "      <td>1166 Geneva Ave</td>\n",
       "      <td>http://www.yelp.com/biz/broken-record-san-fran...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94112</td>\n",
       "      <td>Broken Record 1166 Geneva Ave</td>\n",
       "      <td>[poached, panna, honey, blood, cotta, orange, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>Dessert</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>1166 Geneva Ave, San Francisco, CA, 94112</td>\n",
       "      <td>caramel dip, sea salt</td>\n",
       "      <td>TCHO Chocolate Cheesecake</td>\n",
       "      <td>$6.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>american</td>\n",
       "      <td>Broken Record</td>\n",
       "      <td>CA</td>\n",
       "      <td>1166 Geneva Ave</td>\n",
       "      <td>http://www.yelp.com/biz/broken-record-san-fran...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94112</td>\n",
       "      <td>Broken Record 1166 Geneva Ave</td>\n",
       "      <td>[cheesecake, salt, chocolate, caramel, sea, tc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>Sandwiches</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>1166 Geneva Ave, San Francisco, CA, 94112</td>\n",
       "      <td>Avocado, lettuce, onion, special sauce, crystal</td>\n",
       "      <td>Southern Fried Oysters</td>\n",
       "      <td>$10.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>american</td>\n",
       "      <td>Broken Record</td>\n",
       "      <td>CA</td>\n",
       "      <td>1166 Geneva Ave</td>\n",
       "      <td>http://www.yelp.com/biz/broken-record-san-fran...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94112</td>\n",
       "      <td>Broken Record 1166 Geneva Ave</td>\n",
       "      <td>[onion, crystal, southern, avocado, lettuce, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>Sandwiches</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>1166 Geneva Ave, San Francisco, CA, 94112</td>\n",
       "      <td>House-ground beef &amp; bacon patty american chees...</td>\n",
       "      <td>Beef and Bacon Burger</td>\n",
       "      <td>$10.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>american</td>\n",
       "      <td>Broken Record</td>\n",
       "      <td>CA</td>\n",
       "      <td>1166 Geneva Ave</td>\n",
       "      <td>http://www.yelp.com/biz/broken-record-san-fran...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94112</td>\n",
       "      <td>Broken Record 1166 Geneva Ave</td>\n",
       "      <td>[cheese, beef, houseground, lettuce, house, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>Sandwiches</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>1166 Geneva Ave, San Francisco, CA, 94112</td>\n",
       "      <td>Wilgenberg tomato spicy mayo &amp; honey mustard d...</td>\n",
       "      <td>Crispy Pork Tenderloin Sandwich</td>\n",
       "      <td>$9.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>american</td>\n",
       "      <td>Broken Record</td>\n",
       "      <td>CA</td>\n",
       "      <td>1166 Geneva Ave</td>\n",
       "      <td>http://www.yelp.com/biz/broken-record-san-fran...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94112</td>\n",
       "      <td>Broken Record 1166 Geneva Ave</td>\n",
       "      <td>[tomato, pork, sandwich, mustard, tenderloin, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category_description category_name           city  \\\n",
       "0                            Dessert  San Francisco   \n",
       "1                            Dessert  San Francisco   \n",
       "2                         Sandwiches  San Francisco   \n",
       "3                         Sandwiches  San Francisco   \n",
       "4                         Sandwiches  San Francisco   \n",
       "\n",
       "                                full_address  \\\n",
       "0  1166 Geneva Ave, San Francisco, CA, 94112   \n",
       "1  1166 Geneva Ave, San Francisco, CA, 94112   \n",
       "2  1166 Geneva Ave, San Francisco, CA, 94112   \n",
       "3  1166 Geneva Ave, San Francisco, CA, 94112   \n",
       "4  1166 Geneva Ave, San Francisco, CA, 94112   \n",
       "\n",
       "                                    item_description  \\\n",
       "0                      poached kumquats, local honey   \n",
       "1                              caramel dip, sea salt   \n",
       "2    Avocado, lettuce, onion, special sauce, crystal   \n",
       "3  House-ground beef & bacon patty american chees...   \n",
       "4  Wilgenberg tomato spicy mayo & honey mustard d...   \n",
       "\n",
       "                         item_name item_price  num_reviews  \\\n",
       "0         Blood Orange Panna Cotta      $6.00       1203.0   \n",
       "1        TCHO Chocolate Cheesecake      $6.00       1203.0   \n",
       "2           Southern Fried Oysters     $10.00       1203.0   \n",
       "3            Beef and Bacon Burger     $10.00       1203.0   \n",
       "4  Crispy Pork Tenderloin Sandwich      $9.00       1203.0   \n",
       "\n",
       "  restaurant_category restaurant_name state   street_address  \\\n",
       "0            american   Broken Record    CA  1166 Geneva Ave   \n",
       "1            american   Broken Record    CA  1166 Geneva Ave   \n",
       "2            american   Broken Record    CA  1166 Geneva Ave   \n",
       "3            american   Broken Record    CA  1166 Geneva Ave   \n",
       "4            american   Broken Record    CA  1166 Geneva Ave   \n",
       "\n",
       "                                           yelp_link  yelp_rating    zip  \\\n",
       "0  http://www.yelp.com/biz/broken-record-san-fran...          4.0  94112   \n",
       "1  http://www.yelp.com/biz/broken-record-san-fran...          4.0  94112   \n",
       "2  http://www.yelp.com/biz/broken-record-san-fran...          4.0  94112   \n",
       "3  http://www.yelp.com/biz/broken-record-san-fran...          4.0  94112   \n",
       "4  http://www.yelp.com/biz/broken-record-san-fran...          4.0  94112   \n",
       "\n",
       "                name_and_address  \\\n",
       "0  Broken Record 1166 Geneva Ave   \n",
       "1  Broken Record 1166 Geneva Ave   \n",
       "2  Broken Record 1166 Geneva Ave   \n",
       "3  Broken Record 1166 Geneva Ave   \n",
       "4  Broken Record 1166 Geneva Ave   \n",
       "\n",
       "                                              tokens  \n",
       "0  [poached, panna, honey, blood, cotta, orange, ...  \n",
       "1  [cheesecake, salt, chocolate, caramel, sea, tc...  \n",
       "2  [onion, crystal, southern, avocado, lettuce, s...  \n",
       "3  [cheese, beef, houseground, lettuce, house, ma...  \n",
       "4  [tomato, pork, sandwich, mustard, tenderloin, ...  "
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_menus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:my_projects_env]",
   "language": "python",
   "name": "conda-env-my_projects_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
